<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:base="http://www.dc4plus.com/references/rdf_sem.html" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:foaf="http://xmlns.com/foaf/0.1/" >
    <head>
        <title>Interpretable Neural Architectures for Attributing an Ad’s Performance to its Writing Style</title>
        
        <meta charset="utf-8" />
        <meta content="width=device-width, initial-scale=1" name="viewport" />
        <link href="https://dokie.li/media/css/basic.css" media="all" rel="stylesheet" title="Basic" />
        <link disabled="" href="https://dokie.li/media/css/lncs.css" media="all" rel="stylesheet alternate" title="LNCS" />
        <link href="https://dokie.li/media/css/acm.css" media="all" rel="stylesheet" title="ACM" />
        <link href="https://dokie.li/media/css/do.css" media="all" rel="stylesheet" />
        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" rel="stylesheet" />
        <script src="https://dokie.li/scripts/simplerdf.js"></script>
        <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
        <script src="https://dokie.li/scripts/do.js"></script><script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    </head>
	<body about="" id="article" typeof="schema:ScholarlyArticle sioc:Post prov:Entity foaf:Document sioc:Post biblio:Paper bibo:Document as:Article" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#">
        <main>
            <article about="" typeof="schema:Article">
	  	        <div class="article-content" id="content">
                    
                    <p><div class="article-part article-title" property="schema:name"><h1 class="article-part article-title" property="schema:name">Interpretable Neural Architectures for Attributing an Ad’s Performance to its Writing Style</h1></div></p><div class="article-part metadata article-authors" id="authors"><dd id="ReidPryzantEmail:rpryzant@stanford.edu(StanfordUniversity)" rel="bibo:authorList" resource="#ReidPryzantEmail:rpryzant@stanford.edu(StanfordUniversity)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Reid  Pryzant <i>Email: rpryzant@stanford.edu</i> (Stanford University)
                        </span>
                    </dd><dd id="KazooSoneEmail:sone@google.com(Google)" rel="bibo:authorList" resource="#KazooSoneEmail:sone@google.com(Google)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Kazoo Sone <i>Email: sone@google.com</i> (Google)
                        </span>
                    </dd><dd id="SugatoBasuEmail:sugato@google.com(Google)" rel="bibo:authorList" resource="#SugatoBasuEmail:sugato@google.com(Google)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Sugato Basu <i>Email: sugato@google.com</i> (Google)
                        </span>
                    </dd></div><p><section id="Abstract" class="article-part metadata article-abstract" datatype="rdf:HTML" property="schema:abstract"><p>How much does “free shipping!” help an advertisement’s ability to persuade? This paper presents two methods for performance attribution: finding the degree to which an outcome can be attributed to parts of a text while controlling for potential confounders1 . Both algorithms are based on interpreting the behaviors and parameters of trained neural networks. One method uses a CNN to encode the text, an adversarial objective function to control for confounders, and projects its weights onto its activations to interpret the importance of each phrase towards each output class. The other method leverages residualization to control for confounds and performs interpretation by aggregating over learned word vectors. We demonstrate these algorithms’ ef- ficacy on 118,000 internet search advertisements and outcomes, finding language indicative of high and low click through rate (CTR) regardless of who the ad is by or what it is for. Our results suggest the proposed algorithms are high performance and data efficient, able to glean actionable insights from fewer than 10,000 data points. We find that quick, easy, and authoritative language is associated with success, while lackluster embellishment is related to failure. These findings agree with the advertising industry’s emperical wisdom, automatically revealing insights which previously required manual A/B testing to discover.</p></section></p><div class="article-part article-body"><section id="1Introduction" inlist="" rel="schema:hasPart" resource="#1Introduction">
                            <h2 property="schema:name">1 Introduction </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#1Introduction" typeof="deo:Introduction">
			                <p>A text’s style can affect our cognitive responses and attitudes, thereby influencing behavior (Spence, 1983; Van Laer et al., 2013). The predictive relationship between language and behavior has been well studied in applications of NLP to ∗This work was conducted while the first author was doing internship at Google. 1Our code is available at github.com/rpryzant/ deconfounded_lexicon_induction/tree/ master/text-performance-attribution tasks like linking text to sales figures (Ho and Wu, 1999; Pryzant et al., 2017) and voter preference (Luntz, 2007; Ansolabehere and Iyengar, 1995). In this paper, we are interested in interpreting rather than predicting the relationship between language and behavior. We focus on a specific instance: the relationship between the way a search advertisement is written and internet user behavior as measured by click through rate (CTR). In this study CTR is the ratio of clicks to impressions over a 90-day period, i.e. the probability of a click, given the person saw the ad. Our goal is to develop a method for performance attribution in textual advertisements: identifying lexical features (words, phrases, etc.) to which we can attribute the success (or failure) of a search ad, regardless of who created the advertisement or what it is selling. Identifying linguistic features that are associated with various outcomes is a common activity among machine learning scientists and practitioners. Indeed, it is essential for developing transparent and interpretable machine learning NLP models (Yamamoto, 2012). However, the various forms of regression and association quantifiers like mutual information or log-odds ratio that are the de-facto standard for feature weighting and text attribution all have known drawbacks, largely related to problems of multicollinearity (Imai and Kim, 2016; Gelman and Loken, 2014; Wurm and Fisicaro, 2014; Estevez et al. ´ , 2009; Szumilas, 2010). Furthermore, these prior methods of text attribution critically fail to disentangle the explanatory power of the text from that of confounding information which could also explain the outcome. For example, in movie reviews, the actors who star in a film are the most powerful predictors of box of- fice success (Joshi et al., 2010). However, these are words that the film’s marketers can’t change. Likewise, the name of a well-known brand in an ad for shoes might boost its effectiveness, but if we attribute the ad’s success to the brand terms, we are actually crediting the power of the brand, not necessarily an actionable writing strategy (Ghose and Sundararajan, 2006). There is an emerging line of work on text understanding for confound-controlled settings (Johansson et al., 2016; Egami et al., 2017; Pryzant et al., 2018; Li et al., 2018), but these methods are usually concerned with making causal inferences using text. They are limited to word-features and can only tell you whether a word is discriminative. Attribution involves the more fine-grained problem of identifying discriminative subsequences of the text and being able to explain which level of the outcome these subsequences support. We present a pair of new algorithms for solving this problem. Based on the Adversarial and Residualizing models of (Pryzant et al., 2018), these algorithms first train a machine learning model and then analyze the trained parameters on strategically chosen inputs to infer the most important features for each output class. Our first algorithm encodes the text with a convolutional neural network (CNN) and proceeds to predict the outcome and adversarially predict the confounders. We select attributional n-grams by projecting back the weights of the output layer onto the encoder’s convolutional feature maps. Our second algorithm uses a bag-of-words text representation and is trained to learn the part of the text’s effect that the confounds cannot explain. We get n-grams from this method by tracing back the contribution of each feature towards each outcome class. We demonstrate these algorithms’ efficacy by conducting attribution studies on high- and lowperforming search advertisements across three domains: real estate, job listings, and apparel. We find the proposed algorithms lend importance to words that are more predictive and less confoundrelated than a variety of strong baselines. </p></div>
                    	</section><section id="2TextAttribution" inlist="" rel="schema:hasPart" resource="#2TextAttribution">
                            <h2 property="schema:name">2 Text Attribution </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#2TextAttribution" typeof="">
			                <p>We begin by proposing a methodological framework for text attribution and formalizing the activity into a concrete task.  </p><figure data-equation="" data-image="13" data-figure-category="figure" data-caption="" id="F57801451" data-image-src="/media/images/0f256541-5ca1-41cd-8dc7-317c61ca9f9b.png"><div><img src="0f256541-5ca1-41cd-8dc7-317c61ca9f9b.png"/></div><figcaption><span class="figure-cat-figure" data-figure-category="figure">figure 1: </span></figcaption></figure></div>
                    	</section><section id="3ProposedAlgorithms" inlist="" rel="schema:hasPart" resource="#3ProposedAlgorithms">
                            <h2 property="schema:name">3 Proposed Algorithms</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#3ProposedAlgorithms" typeof="">
			                <p> We continue by describing the pair of novel algorithms we are proposing to use for text attribution. Each algorithm consists of two phases: training, where we use T, Y , and C to train a machine learning model, and interpretation, where we analyze the learned parameters to identify attributional language. </p></div>
                    	</section><section id="3.1ConvolutionalAdversarialSelector(CA)Training." inlist="" resource="#3.1ConvolutionalAdversarialSelector(CA)Training.">
                            <h3 property="schema:name">3.1 Convolutional Adversarial Selector (CA) Training.</h3>
                        <p> We begin by observing that the language we want to attribute should be able to explain the variation in Y and should also be decorrelated from the confounders C. This implies that the features we want to select should be predictive of Y , but not C (e.g. brand name). The Convolutional Adversarial Selector (CA) draws inspiration from this. It adversarially learns encodings of T which are useful for predicting Y but are not useful for predicting C. The model is depicted on the left-hand side of Figure 1. First, we encode T into e ∈ Rf with the following steps:</p><ol><li><figure data-equation="" data-image="14" data-figure-category="figure" data-caption="" id="F1032871" data-image-src="/media/images/d44517b7-f1a3-4a6e-865d-9304a3429217.png"><div><img src="d44517b7-f1a3-4a6e-865d-9304a3429217.png"/></div><figcaption><span class="figure-cat-figure" data-figure-category="figure">figure 2: </span></figcaption></figure><p><strong>Interpretation</strong>. Once we’ve trained a CA model, we interpret its behavior in order to determine the most important n-grams for each level of the outcome.<span class="comment ref do" data-id="835103590" rel="schema:hasPart" typeof="dctypes:Text" resource="r-835103590"><mark id="835103590" property="schema:description">
                         
                    </mark><sup class="ref-annotation">
    		        <a rel="cito:hasReplyFrom" href="#835103590" resource="http://localhost:8000/document/10//comment-835103590">
       		              💬
                    </a>
                </sup></span></p><section id="4Experiments" inlist="" rel="schema:hasPart" resource="#4Experiments">
                            <h2 property="schema:name">4 Experiments </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#4Experiments" typeof="deo:Evaluation">
			                <p>We demonstrate the efficacy of the proposed algorithms on a dataset of internet advertisements. </p><p></p></div>
                    	</section></li></ol><p><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:0}]">(Ansolabehere &amp; Iyengar, 1995)</span><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:1115933143}]">(Baayen, Kuperman, &amp; Bertram, 2010)</span></p><aside class="note do"><blockquote cite="835103590"><article id="835103590" about="i:" typeof="oa:Annotation" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# schema: http://schema.org/ dcterms: http://purl.org/dc/terms/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# i: http://localhost:8000/document/10/#835103590"><h3 property="schema:name" style="display:none">
    Wrishi
    <span rel="oa:motivatedBy" resource="oa:replying">replies</span>
</h3>
<dl class="author-name"><dt>Authors</dt><dd><span rel="schema:creator">
    <span about="userURI#1" typeof="schema:Person">
       <img alt="" rel="schema:image" src="https://www.gravatar.com/avatar/0397eeb87e26782f66df823775d58a71/?s=80" width="48" height="48"/>
       <a href="#"><span about="userURI#1" property="schema:name">
           Wrishi
       </span></a>
    </span>
</span></dd></dl>
<dl class="published">
    <dt>Published</dt>
    <dd>
        <a href="http://localhost:8000/document/10/#835103590">
            <time datetime="1540461083403" datatype="xsd:dateTime" property="schema:datePublished" content="1540461083403">
                1540461083403
            </time>
        </a>
    </dd>
</dl>
<section id="comment-835103590" rel="oa:hasBody" resource="i:#comment-835103590">
    <h2 property="schema:name">Comment</h2>
    <div datatype="rdf:HTML" property="rdf:value schema:description" resource="i:#comment-835103590" typeof="oa:TextualBody">
        Ok. Doing what must be done.
    </div>
</section>

<br/><br/></article></blockquote></aside></section></div><h1 class="article-bibliography-header"></h1><section id="references">
			            <h2>References</h2>
                        <div datatype="rdf:HTML" rel="schema:hasPart" typeof="deo:Reference">
                            <ol>
  <li><cite>Ansolabehere, S., &amp; Iyengar, S. (Eds.). (1995). Going Negative: How Attack Ads Shrinks and Polarize the Electorate. New York: Free Press.</cite></li>
  <li><cite>Baayen, R. H., Kuperman, V., &amp; Bertram, R. (Eds.). (2010). Frequency effects in compound processing.</cite></li>
</ol>
			            </div>
                    </section><script>jQuery( document ).ready(function() {
    			        jQuery(this).find('span.comment').each(function () {
                            var id=jQuery(this).attr('data-id');
                            var top=jQuery(this).offset().top - 40;
                            jQuery(document).find('article[id="'+id+'"]').each(function () {
                                jQuery(this).css('top',top);
                            });
                        });
                    });</script>
			    </div>
			</article>
		</main>
	</body>
</html>