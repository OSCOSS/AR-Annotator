<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:base="http://www.dc4plus.com/references/rdf_sem.html" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:foaf="http://xmlns.com/foaf/0.1/" >
    <head>
        <title>Textual Analogy Parsing: What’s Shared and What’s Compared among Analogous Facts</title>
        
        <meta charset="utf-8" />
        <meta content="width=device-width, initial-scale=1" name="viewport" />
        <link href="https://dokie.li/media/css/basic.css" media="all" rel="stylesheet" title="Basic" />
        <link disabled="" href="https://dokie.li/media/css/lncs.css" media="all" rel="stylesheet alternate" title="LNCS" />
        <link href="https://dokie.li/media/css/acm.css" media="all" rel="stylesheet" title="ACM" />
        <link href="https://dokie.li/media/css/do.css" media="all" rel="stylesheet" />
        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" rel="stylesheet" />
        <script src="https://dokie.li/scripts/simplerdf.js"></script>
        <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
        <script src="https://dokie.li/scripts/do.js"></script><script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    </head>
	<body about="" id="article" typeof="schema:ScholarlyArticle sioc:Post prov:Entity foaf:Document sioc:Post biblio:Paper bibo:Document as:Article" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#">
        <main>
            <article about="" typeof="schema:Article">
	  	        <div class="article-content" id="content">
                    
                    <p><div class="article-part article-title" property="schema:name"><h1 class="article-part article-title" property="schema:name">Textual Analogy Parsing: What’s Shared and What’s Compared among Analogous Facts</h1></div></p><div class="article-part metadata article-authors" id="authors"><dd id="MatthewLammEmail:mlamm@stanford.edu(StanfordLinguistics)" rel="bibo:authorList" resource="#MatthewLammEmail:mlamm@stanford.edu(StanfordLinguistics)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Matthew Lamm <i>Email: mlamm@stanford.edu</i> (Stanford Linguistics)
                        </span>
                    </dd><dd id="DanJurafskyEmail:jurafsky@stanford.edu(StanfordNLPGroup)" rel="bibo:authorList" resource="#DanJurafskyEmail:jurafsky@stanford.edu(StanfordNLPGroup)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Dan Jurafsky <i>Email: jurafsky@stanford.edu</i> (Stanford NLP Group)
                        </span>
                    </dd></div><p><section id="Abstract" class="article-part metadata article-abstract" datatype="rdf:HTML" property="schema:abstract"><p>To understand a sentence like “whereas only 10% of White Americans live at or below the poverty line, 28% of African Americans do” it is important not only to identify individual facts, e.g., poverty rates of distinct demographic groups, but also the higher-order relations between them, e.g., the disparity between them. In this paper, we propose the task of Textual Analogy Parsing (TAP) to model this higher-order meaning. The output of TAP is a frame-style meaning representation which explicitly specifies what is shared (e.g., poverty rates) and what is compared (e.g., White Americans vs. African Americans, 10% vs. 28%) between its component facts. Such a meaning representation can enable new applications that rely on discourse understanding such as automated chart generation from quantitative text. We present a new dataset for TAP, baselines, and a model that successfully uses an ILP to enforce the structural constraints of the problem. </p></section></p><div class="article-part article-body"><section id="1Introduction" inlist="" rel="schema:hasPart" resource="#1Introduction">
                            <h2 property="schema:name">1 Introduction</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#1Introduction" typeof="deo:Introduction">
			                <p> The task of information extraction by and large seeks to populate a knowledge base with individuated facts extracted from text (Sarawagi, 2008). For example, given the sentence: (E1) [According to the U.S. Census, whereas only 10% of White Americans live at or below the poverty line today]C1, [28% of African Americans do.]C2 1 one would extract two independent facts about voter registration, about the two distinct demographic groups. On the other hand, the theory of discourse maintains that part of the above sentence’s meaning inheres in the fact that clauses C1 ∗Author contributed significantly. 1Data in E1 and the figure sentence from Morris (2014). According to the U.S. Census , almost 10.9 million African Americans , or 28% ,  live at or below the poverty line , compared with 15% of Latinos and approximately 10% of White Americans .  Thus the author intends that we consider them in relation to each other, inviting us to note, for example, a disparity of wealth distribution between demographic groups. To fail to capture this is to miss out on an important aspect of text understanding. We propose the task of Textual Analogy Parsing (TAP) to explicitly capture such relational meaning between analogous facts in text. Concretely, TAP first maps a set of analogous facts to semantic role (SRL) representations, and then identifies the roles along which they are similar (the shared content) and along which they are distinct (the compared content)—see Figure 1. The resulting representation, the TAP frame, is a deeper representation than the one output by shallow discourse parsers (Taboada and Mann, 2006; Prasad et al., 2007; Pitler et al., 2009; Prasad et al., 2010;We model TAP by jointly predicting SRL representations of facts in a sentence, and higherorder semantic relations between them. Our main findings are that a neural architecture outperforms a log-linear baseline, well-chosen linguistic features help performance, and so does the use of an integer-linear programming (ILP) decoder that enforces the structural constraints of the task. Nevertheless, both quantitative and qualitative evaluation reveal room for improvement on TAP. In sum, our main contributions are (1) a new task, Textual Analogy Parsing (TAP), that combines shallow semantic parsing with discourse meaning, (2) a dataset of TAP frames from quantitative newswire, and (3) a preliminary study of a new application, automated chart generation from text. All data and code, including standardized evaluation scripts, are made freely available. </p><figure data-equation="" data-image="17" data-figure-category="figure" data-caption="" id="F13530681" data-image-src="/media/images/bec7c934-bbcf-4597-92fd-0a5f4dcddf2b.jpg"><div><img src="bec7c934-bbcf-4597-92fd-0a5f4dcddf2b.jpg"/></div><figcaption><span class="figure-cat-figure" data-figure-category="figure">figure 1: </span></figcaption></figure></div>
                    	</section><section id="2ASemanticRepresentationofAnalogy" inlist="" rel="schema:hasPart" resource="#2ASemanticRepresentationofAnalogy">
                            <h2 property="schema:name">2 A Semantic Representation of Analogy</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#2ASemanticRepresentationofAnalogy" typeof="deo:Model">
			                <p> Let us revisit the example sentence from the previous section (E1), where a pair of analogous quantitative facts about poverty rates of different demographic groups are presented in contrast. they are analogous, i.e., structurally and semantically similar but distinct. Instead, we can explicitly show points of similarity and difference between them in the twotiered frame structure in Figure 2, which we call a TAP frame. The outer tier of the TAP frame contains shared content, or information pertinent to all of the facts in question, and the inner tier contains compared content, the information that varies across the set of facts. Mapping from an utterance to a TAP frame requires three types of relational reasoning. Firstly, one must decompose the utterance into a set of facts, where a fact is represented as a set of semantic roles. Then, one must identify the shared content across facts by aligning roles that are semantically equivalent, in the sense that they are either the same span, are coreferent, or are synonymous. For example, in Figure 2 the phrase ‘U.S. Census’ occurs as the SOURCE of both facts because it scopes over the entire sentence in which they appear. Additionally, one must identify the compared content by aligning roles that are analogous, in the sense that they are semantically similar but nevertheless distinct. For example, the phrases ‘White Americans’ and ‘African Americans’ are analogous in our running sentence, playing the same role in their respective facts, while signifying distinct demographic groups. </p></div>
                    	</section><section id="3TheQuantitativeTAPDataset" inlist="" rel="schema:hasPart" resource="#3TheQuantitativeTAPDataset">
                            <h2 property="schema:name">3 The Quantitative TAP Dataset</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#3TheQuantitativeTAPDataset" typeof="">
			                <p> Motivated by the application of automated graphical plot generation from text, we annotated a dataset of quantitative TAP frames from the Penn Treebank WSJ corpus (Marcus et al., 1999). <span class="comment ref do" data-id="3785674273" rel="schema:hasPart" typeof="dctypes:Text" resource="r-3785674273"><mark id="3785674273" property="schema:description">
                        As our SRL representation of quantitative facts, we employ the Quantitative Semantic Role Labeling (QSRL) framework we previously defined in Lamm et al. (2018). Having identified a numerical VALUE in text (e.g., 10%), QSRL asks, “what does this number measure?” 
                    </mark><sup class="ref-annotation">
    		        <a rel="cito:hasReplyFrom" href="#3785674273" resource="http://localhost:8000/document/12//comment-3785674273">
       		              💬
                    </a>
                </sup></span>to determine its associated QUANTITY (e.g., a poverty rate). It might also identify, for example, the WHOLE out of which this percentage is measured (e.g., the set of African Americans), and the TIME at which the quantity took on the value (e.g., today), etc. We employ all fifteen QSRL roles in our annotations. Our annotations not only capture the relation between a quantitative predicate and its arguments, but also the higher-order analogy relations between them. The distinction is reflected in the sentences in Table 1 from the dataset: Colored spans are co-indexed when they participate in the same quantitative fact; spans with like roles surrounded by parentheses are shared content, meaning that they are either synonymous or co-referent; spans with like roles surrounded by brackets are compared content, meaning that they are analogous but semantically distinct. To identify instances of quantitative analogy in the WSJ corpus, we first prune out any sentence having fewer than three numerical mentions, where a numerical mention is defined as a contiguous sequence of CD POS tags. Of those left, we manually identify those containing one or more quantitative analogies, i.e., ones in which numerical values are compared content. We estimate the incidence of these to be around 20%. A linguist then annotated 1,100 of these for analogy relationships. See Table 2 for a summary. Using an independent set of expert annotations on 100 of these sentences, we measured a signifi- cant per-token label agreement of 0.882 and edge label agreement of 0.991 using Krippendorf’s α. 2 Table 1 highlights some of the challenging linguistic phenomena in the data. With respect to identifying the shared content of a TAP frame, these can be coarsely divided into two sets. Firstly, in scope, ellipsis, and gapping, a single syntactic element serves as a role in multiple QSRL frames. This is exemplified by the phrase ‘PS of New Hampshire’ in Table 1(a): It is mentioned explicitly as a THEME of the first fact, and only implied in the second two. Based on a random sample of 100 train sentences, we estimate that 86% of frames in the data exhibit these phenomena. Secondly, in synonymy and coreference, multiple elements appear in a sentence but contribute the same role to the shared content, e.g., ‘offered’ and ‘bid’ in Table 1(a). We estimate that 31% of frames in 2High edge agreement should be expected because edges are type-constrained and thus easy to identify. Additionally, we computed agreement after matching overlapping spans. the data exhibit these phenomena. One must learn to identify analogy relationships over a diverse set of compared content roles, with distinct semantic properties: in Table 1(a), AGENT is a compared content role, whereas in Table 1(b), CAUSE is. </p></div>
                    	<aside class="note do"><blockquote cite="3785674273"><article id="3785674273" about="i:" typeof="oa:Annotation" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# schema: http://schema.org/ dcterms: http://purl.org/dc/terms/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# i: http://localhost:8000/document/12/#3785674273"><h3 property="schema:name" style="display:none">
    Wrishi
    <span rel="oa:motivatedBy" resource="oa:replying">replies</span>
</h3>
<dl class="author-name"><dt>Authors</dt><dd><span rel="schema:creator">
    <span about="userURI#1" typeof="schema:Person">
       <img alt="" rel="schema:image" src="https://www.gravatar.com/avatar/0397eeb87e26782f66df823775d58a71/?s=80" width="48" height="48"/>
       <a href="#"><span about="userURI#1" property="schema:name">
           Wrishi
       </span></a>
    </span>
</span></dd></dl>
<dl class="published">
    <dt>Published</dt>
    <dd>
        <a href="http://localhost:8000/document/12/#3785674273">
            <time datetime="1540461303013" datatype="xsd:dateTime" property="schema:datePublished" content="1540461303013">
                1540461303013
            </time>
        </a>
    </dd>
</dl>
<section id="comment-3785674273" rel="oa:hasBody" resource="i:#comment-3785674273">
    <h2 property="schema:name">Comment</h2>
    <div datatype="rdf:HTML" property="rdf:value schema:description" resource="i:#comment-3785674273" typeof="oa:TextualBody">
        Today
    </div>
</section>

<br/><br/></article></blockquote></aside></section><section id="4ModelingTAPintheQuantitativeSetting" inlist="" rel="schema:hasPart" resource="#4ModelingTAPintheQuantitativeSetting">
                            <h2 property="schema:name">4 Modeling TAP in the Quantitative Setting</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#4ModelingTAPintheQuantitativeSetting" typeof="deo:Model">
			                <p> We model TAP by generating a typed analogy graph over spans of an input text that is isomorphic to the set of TAP frames in that text, e.g., Figure 2. Each vertex in the graph corresponds to a role-labeled span, and edges represent semantic relations between them. In this graph, each fact is uniquely identified by a VALUE vertex, which is connected via a FACT edge to all of its associated roles. Any two shared content vertices across facts are connected by an EQUIVALENCE edge, indicating that they are coreferent or synonymous. A single vertex can also be shared across facts by linking via a FACT edge to more than one VALUE vertex, suggesting a scopal relationship.For G so defined to encode a set of valid TAP frames, it must satisfy certain constraints: </p><ol><li><p><strong>Well-formedness constraints.</strong>  Furthermore, every vertex must participate in at least one FACT edge, i.e., no disconnected vertices. </p></li><li><p><strong>Typing constraints.</strong> FACT relations are always drawn from a VALUE vertex to a nonVALUE vertex. ANALOGY and EQUIVALENCE are only ever drawn between two vertices of the same role. </p></li><li><p><strong>Unique facts.</strong> If a VALUE vertex v is connected to two distinct vertices v 0 and v 00 of the same role via a FACT edge, then EQUIVALENCE(v 0 , v00) exists.</p></li><li><p><strong>Transitivity constraints.</strong> ANALOGY and EQUIVALENCE edges are transitive: if EQUIVALENCE(v, v0 ) ∈ E and EQUIVALENCE(v 0 , v00) ∈ E then EQUIVALENCE(v, v00) ∈ E also. This also holds for ANALOGY edges, but only when v, v0 and v 00 are VALUE vertices. </p></li><li><p><strong>Analogy.</strong> There must be at least one pair of analogous VALUE vertices, and for each such pair, there must be a pair of analogous facts connected to them: if v, v0 are two VALUE vertices with ANALOGY(v, v0 ) ∈ E, then there must also exist w, w0 as two non-VALUE vertices with FACT(v, w) ∈ E, FACT(v 0 , w0 ) ∈ E, ANALOGY(w, w0 ) ∈ E. Note that while these constraints rely on the choice of VALUE as the role that grounds quantitative facts, they reflect the general idea that analogy is a structured mapping between meaning representations. </p></li></ol></div>
                    	</section><section id="5ANeuralandILPModelforTAP" inlist="" rel="schema:hasPart" resource="#5ANeuralandILPModelforTAP">
                            <h2 property="schema:name">5 A Neural and ILP Model for TAP</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#5ANeuralandILPModelforTAP" typeof="deo:Model">
			                <p> We now present a neural and ILP model that predicts analogy graphs as defined in Section 4. Given a sentence, the neural model predicts a distribution over role-labeled spans with edges denoting semantic relations between them. Then, we use an ILP to decode while enforcing the TAP constraints defined in Section 4. Figure 4 presents an overview of the architecture. </p><p><strong>Context-sensitive word embeddings.</strong> We first encode the words in a sentence by embedding each token using fixed word embeddings. We also concatenate a few linguistic features to the word embeddings, such as named entity tags and dependency relations. These features are generated using CoreNLP (Manning et al., 2014) and represented by randomly-initialized, learned embeddings for symbols together with the fixed word embedding of each token’s dependency head and the dependency path length between adjacent tokens. The token embeddings are then passed through several stacked convolutional layers (Kim, 2014). While the first convolutional layer can only capture local information, subsequent layers allow for longer-distance reasoning. </p><p><strong>Span prediction.</strong> Next, we feed the outputs of a single fully-connected hidden layer to a conditional random field (CRF) (Lafferty et al., 2001), x stacked convolution xˆ CRF sm emn pm FF pmn decoder G sentence embedding span embedding edge embedding predicted spans predicted edges output input sentence Figure 4: An overview of the proposed neural model: The sentence embedding represents features across the entire sentence using multiple convolutional layers. We then use a conditional random field (CRF) layer to predict labeled spans pm and to generate span and edge embeddings. We use a feedforward (FF) layer on the edge embeddings to predict edge labels pmn. Together, pm and pmn form a distribution over edges and labels that we decode into TAP frames. which defines a joint distribution over per-token role labels. We thus obtain spans from this distribution corresponding to vertices of the graph described in Section 4 by merging contiguous rolelabels in the maximum likelihood label sequence predicted by the CRF. </p><p><strong>Edge prediction with PATHMAX features.</strong> For edge prediction, we use the spans identified above to construct span and edge embeddings: for every span (i, j) that was predicted, we construct a span vector sm = Pj k=i xˆk. We also construct a rolelabel score vector for the span, pm by summing the role-label probability vectors of its constituent tokens. Then, for every vertex pair (m, n), we construct an edge representation emn. The basis of this representation is simply the concatenation of the span representations, the sum of the span representations, their respective role-label score vectors pm and pn, and relative token distances. To capture long-distance phenomena like scope, we also incorporate features into emn from the dependency paths between the two spans by maxpooling the (learned) dependency relation embeddings along the path between the tokens.3 When computing the representation between two spans, we take the average of the path embedding between each pair of tokens within them. We call 3The dependency paths are directed but unlexicalized. this extension PATHMAX. The resulting edge representation emn is passed through a single fully-connected hidden layer and an output layer to predict a distribution over edge labels pmn, for each pair of spans. </p><p><strong>Training.</strong> The supervised data described in Section 3 provides gold spans and edges between them. Thus we define a loss function with two terms: one for the log-likelihood of the span labels output by the CRF model, and one for the crossentropy loss on the edge labels. We train the span and edge components of the model jointly. </p><p><strong>Decoding.</strong> We consider two methods for decoding the span-level and edge-level label distributions pm and pm,n into a labeled graph respecting the constraints described in Section 4. As a simple greedy method to enforce these constraints, we begin by picking the most likely role for each span and edge and then discarding any edges and spans that violate the wellformedness (1) and typing constraints (2). We then enforce transitivity constraints (4) by incrementally building a cluster of analogous and equivalent spans. We then resolve the unique facts constraint (3) by keeping only the span with highest FACT edge score. Finally, for every cluster of analogous VALUE spans, we check that the analogy constraint (5) holds and if not, discard the cluster. We also implement an optimal decoder that encodes the TAP constraints as an ILP (Roth and Yih, 2004; Do et al., 2012). The ILP tries to find an optimal decoding according to the model, subject to hard constraints imposed on the solution space. For example, we require that solutions satisfy the ‘connected spans’ constraint: ∀s∃s 0 : e(s, s0 , FACT) In plain English, this says that every span s in a solution must be connected via a FACT edge to some other span s 0 . See the supplementary material for the full list of constraints we employ. We solve the ILPs with Gurobi (Gurobi Optimization, Inc., 2018). </p></div>
                    	</section><section id="6Experiments" inlist="" rel="schema:hasPart" resource="#6Experiments">
                            <h2 property="schema:name">6 Experiments </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#6Experiments" typeof="deo:Evaluation">
			                <p>We now describe the experimental setup of our neural model (Section 5) on the dataset of TAP frames we created (Section 3). Results and discussion are reported in Section 7.</p><p><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:0}]">(Baker, Fillmore, &amp; Lowe, 1998)</span><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:495446398}]">(Barrio, Goldstein, &amp; Hofman, 2016)</span></p></div>
                    	</section></div><h1 class="article-bibliography-header"></h1><section id="references">
			            <h2>References</h2>
                        <div datatype="rdf:HTML" rel="schema:hasPart" typeof="deo:Reference">
                            <ol>
  <li><cite>Baker, C. F., Fillmore, C. J., &amp; Lowe, J. B. (Eds.). (1998). The Berkeley FrameNet Project.</cite></li>
  <li><cite>Barrio, P. J., Goldstein, D. G., &amp; Hofman, J. M. (Eds.). (2016). Improving Comprehension of Numbers in the News.</cite></li>
</ol>
			            </div>
                    </section><script>jQuery( document ).ready(function() {
    			        jQuery(this).find('span.comment').each(function () {
                            var id=jQuery(this).attr('data-id');
                            var top=jQuery(this).offset().top - 40;
                            jQuery(document).find('article[id="'+id+'"]').each(function () {
                                jQuery(this).css('top',top);
                            });
                        });
                    });</script>
			    </div>
			</article>
		</main>
	</body>
</html>