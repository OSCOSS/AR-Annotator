<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:base="http://www.dc4plus.com/references/rdf_sem.html" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:foaf="http://xmlns.com/foaf/0.1/" >
    <head>
        <title>Evaluating the Quality of the LOD Cloud: An Empirical Investigation</title>
        
        <meta charset="utf-8" />
        <meta content="width=device-width, initial-scale=1" name="viewport" />
        <link href="https://dokie.li/media/css/basic.css" media="all" rel="stylesheet" title="Basic" />
        <link disabled="" href="https://dokie.li/media/css/lncs.css" media="all" rel="stylesheet alternate" title="LNCS" />
        <link href="https://dokie.li/media/css/acm.css" media="all" rel="stylesheet" title="ACM" />
        <link href="https://dokie.li/media/css/do.css" media="all" rel="stylesheet" />
        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" rel="stylesheet" />
        <script src="https://dokie.li/scripts/simplerdf.js"></script>
        <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
        <script src="https://dokie.li/scripts/do.js"></script><script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    </head>
	<body about="" id="article" typeof="schema:ScholarlyArticle sioc:Post prov:Entity foaf:Document sioc:Post biblio:Paper bibo:Document as:Article" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#">
        <main>
            <article about="" typeof="schema:Article">
	  	        <div class="article-content" id="content">
                    
                    <p><div class="article-part article-title" property="schema:name"><h1 class="article-part article-title" property="schema:name">Evaluating the Quality of the LOD Cloud: An Empirical Investigation</h1></div></p><div class="article-part metadata article-authors" id="authors"><dd id="JeremyDebattistaEmail:debattij@tcd.ie(ADAPTCentre,SchoolofComputerScienceandStatistics,TrinityCollegeDublin,Ireland)" rel="bibo:authorList" resource="#JeremyDebattistaEmail:debattij@tcd.ie(ADAPTCentre,SchoolofComputerScienceandStatistics,TrinityCollegeDublin,Ireland)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Jeremy  Debattista <i>Email: debattij@tcd.ie</i> ( ADAPT Centre, School of Computer Science and Statistics, Trinity College Dublin, Ireland)
                        </span>
                    </dd><dd id="ChristophLangeEmail:langec@iai.uni-bonn.de(FraunhoferIAIS,SchlossBirlinghoven,53754SanktAugustin,Germany)" rel="bibo:authorList" resource="#ChristophLangeEmail:langec@iai.uni-bonn.de(FraunhoferIAIS,SchlossBirlinghoven,53754SanktAugustin,Germany)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Christoph Lange <i>Email: langec@iai.uni-bonn.de</i> (Fraunhofer IAIS, Schloss Birlinghoven, 53754 Sankt Augustin, Germany)
                        </span>
                    </dd><dd id="SörenAuerEmail:auer@l3s.de(TIBLeibnizInformationCentreforScienceandTechnology&amp;LeibnizUniversityofHannover,AmWelfengarten1b,30167Hannover,Germany.)" rel="bibo:authorList" resource="#SörenAuerEmail:auer@l3s.de(TIBLeibnizInformationCentreforScienceandTechnology&amp;LeibnizUniversityofHannover,AmWelfengarten1b,30167Hannover,Germany.)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Sören Auer <i>Email: auer@l3s.de</i> (TIB Leibniz Information Centre for Science and Technology &amp; Leibniz University of Hannover, Am Welfengarten 1b, 30167 Hannover, Germany.)
                        </span>
                    </dd><dd id="DominicCortisEmail:dominic.cortis@um.edu.mt(FacultyofEconomics,ManagementandAccountancy,UniversityofMalta,MsidaMSD2080,Malta)" rel="bibo:authorList" resource="#DominicCortisEmail:dominic.cortis@um.edu.mt(FacultyofEconomics,ManagementandAccountancy,UniversityofMalta,MsidaMSD2080,Malta)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Dominic Cortis <i>Email: dominic.cortis@um.edu.mt</i> (Faculty of Economics, Management and Accountancy, University of Malta, Msida MSD 2080, Malta )
                        </span>
                    </dd></div><p><section id="Abstract" class="article-part metadata article-abstract" datatype="rdf:HTML" property="schema:abstract"><p>The increasing adoption of the Linked Data principles brought with it an unprecedented dimension to the Web, transforming the traditional Web of Documents to a vibrant information ecosystem, also known as the Web of Data. This transformation, however, does not come without any pain points. Similar to the Web of Documents, the Web of Data is heterogenous in terms of the various domains it covers. The diversity of the Web of Data is also reflected in its quality. Data quality impacts the fitness for use of the data for the application at hand, and choosing the right dataset is often a challenge for data consumers. In this quantitative empirical survey, we analyse 130 datasets (≈ 3.7 billion quads), extracted from the latest Linked Open Data Cloud using 27 Linked Data quality metrics, and provide insights into the current quality conformance. Furthermore, we publish the quality metadata for each assessed dataset as Linked Data, using the Dataset Quality Vocabulary (daQ). This metadata is then used by data consumers to search and filter possible datasets based on different quality criteria. Thereafter, based on our empirical study, we present an aggregated view of the Linked Data quality in general. Finally, using the results obtained from the quality assessment empirical study, we use the Principal Component Analysis (PCA) test in order to identify the key quality indicators that can give us sufficient information about a dataset’s quality.</p></section></p><div class="article-part metadata article-keywords"><span class="keyword">Data Quality</span><span class="keyword"> Linked Data</span><span class="keyword"> Empirical Study</span><span class="keyword"> Data Quality Survey</span></div><div class="article-part article-body"><section id="Introduction" inlist="" rel="schema:hasPart" resource="#Introduction">
                            <h2 property="schema:name">Introduction</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#Introduction" typeof="deo:Introduction">
			                <p>Since its inception, the Linked Open Data (LOD) Cloud [53] has been a point of reference to the Linked Data community, comprising a number of linked datasets crawled on the Web of Data or added to the LODCloud group in the datahub.io registry1 . The maintainers provide a set of criteria for the inclu- *Corresponding author. E-mail: debattij@tcd.ie 1https://datahub.io/group/lodcloud sion of a dataset within the LOD Cloud; more specifically, datasets should be published according to the Linked Data principles as defined in [11]. The Linked Data principles, closely related to the five star scheme for publishing open data2 , can be summarised as publishing structured, interlinked data, in non-proprietary formats, using URIs.</p><p>This widespread and rapid adoption of the Linked Data principles has brought an unprecedented dimension on the Web, contributing to the transformation of the Web of Documents to a Web of Data. Thanks to links between the data, one can jump from one source to another in order to retrieve more complete information and answers. Similarly to the Web of Documents, these sources, heterogeneous with regard to their domain, have highly varying quality [30]. Document quality is often only subjectively assessable, and indirect measures such as Page Rank and HITS (hubs and authorities), which calculate the importance of a document vis-à-vis the Web (via links), give a good indication of whether a document is of good quality or a good authoritative source. In a parallel situation, resources in the Web of Data are not simply text (or other HTML components such as tables, images) and links. For LOD datasets, indirect link related quality measures are much less meaningful, (since linked datasets are prone to link spamming [26]) but at the same time a number of other more direct quality indicators exist. Linked Data resources are usually complex structures encompassing some existing thing (an object in the real world), giving it semantics (i.e. meaning) and possibly linking to other resources, that both machines and humans can understand. According to the editors of the W3C Data on the Web Best Practices document, “data quality can affect the potentiality of the application that uses data, as a consequence, its inclusion in the data publishing and consumption pipelines is of primary importance.” – [38, §9.5] Making data quality more transparent and easy-toaccess is a key factor for the wider penetration of Linked Data and semantic technologies. In this study, the research question we aim to answer is: What is the quality of existing Linked Data on the Web? To answer this question, we perform a large scale evaluation of Linked Data quality in terms of data size, domain and quality indicator coverage. More specifically we assess and quantify the quality of 130 datasets (≈ 3.7 billion triples) in the Linked Open Data Cloud over a number of quality indicators, as classified in [60]. Furthermore, such an investigation leads to other insights, such as identifying which of the assessed metrics are the most informative to describe the quality of a linked dataset (cf. Section 6.2). Using Luzzu [17], a quality assessment framework for Linked Data, and a number of quality metrics (including some probabilistic approximation metrics), this study produces a quality metadata graph for each assessed dataset (publicly available for consumption as Linked Data resources), represented in terms of the Dataset Quality Vocabulary (daQ) [18]3 . The benefits of these metadata graphs are two-fold: (1) humans can understand the quality of a dataset better, using ranking or visualisation tools, thus making more informed decisions prior to using a dataset; and (2) machines can automatically process the quality metadata of a dataset. The remainder of this article is structured as follows. We first discuss related work regarding analysis of various aspects of Linked Data (Section 2). In Section 3 we perform a primary investigation towards the openness of the Linked Open Data, followed by the dataset acquisition description in Section 4. Following the data acquisition process, in Section 5 we assess and discuss the quality of these datasets against 27 metrics related to four different quality categories as described in [60]. We then use the assessment results in order to identify the non-informative quality metrics in Section 6, followed by the conclusions in Section 7. </p></div>
                    	</section><section id="2.StudyingtheQualityoftheDataontheWeb" inlist="" rel="schema:hasPart" resource="#2.StudyingtheQualityoftheDataontheWeb">
                            <h2 property="schema:name">2. Studying the Quality of the Data on the Web </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#2.StudyingtheQualityoftheDataontheWeb" typeof="">
			                <p>Empirical studies encourage stakeholders to engage in further discussions and enable them to improve the current state of the discussed topic, in this case of the quality of linked datasets. The main contribution of this study is a large-scale analysis of the quality of linked open datasets. We assess various data dumps, SPARQL endpoints that are available and portrayed in the 2014 LOD Cloud snapshot over 27 quality metrics related to different inherent and extrinsic aspects of Linked Data. In this section, we review literature that analyse the quality of various aspects of Linked Data, as a prequel to the large-scale analysis described in this article. Schmachtenberg et al. [54] crawled the Web of Data in order to present the 2014 version of the LOD cloud diagram. Each crawled dataset was categorised in a topical domain, whose categorisation was then used in one of our metrics, re-use of existing terms (Metric IO1). Furthermore, during this study, the authors also analysed how different best practices were adopted in the crawled linked datasets. Some of these best practices overlap with the quality metrics presented in our study, including best practices related to the adoption of vocabularies and metadata. In our work, we use the 2014 version of the LOD cloud to better understand the quality of the Web of Data.4 Throughout the years, a number of researchers in Linked Data quality have come up with numerous quality metrics that were consolidated in a systematic survey by Zaveri et al. in [60]. The authors of this systematic survey group 69 different quality metrics in 18 dimensions and four categories: Accessibility, Intrinsic, Contextual, and Representational. Our empirical investigation towards the quality of the Web of Data complements the survey undertaken in [60], with 27 out of the 69 described metrics being implemented and assessed over a number of datasets (cf. Section 5.1). Based on Zaveri et al. [60] and the ISO 25012 data quality model [34], Radulovic et al. [49] present a quality model for Linked Data, where quality characteristics and their base and derived measures were semantically formalised in a comprehensive model. The model was evaluated on a subset of DBpedia; mainly instances of type Person and Place. Our contribution covers eight of the quality characteristics mentioned in [49] that are also part of [60]. However, our resulting metadata does not have the low granularity level that can be expressed with the model defined by Radulovic et al. [49], as for our study we use Luzzu [17] as our quality assessment framework and the Dataset Quality Vocabulary (daQ) [18] for metadata. Nonetheless, further discussion on the different models and frameworks is out of the scope of this study. In [31], Hogan et al. crawled and assessed the quality of around 12 million RDF statements. The main aim was to discuss common problems found in RDF datasets, and possible solutions. More specifically, this work aimed at uncovering errors related to accessibility, reasoning, syntactical and non-authoritative contributions. The authors also provided suggestions on how publishers can improve their data, so that the consumers can find “higher quality” datasets. 4A more recent version of the LOD cloud was released on 20 February 2017, i.e., after we had conducted our study. In a follow up article [33], Hogan et al. conducted a larger empirical study on Linked Data conformance, with around 1 billion quads (i.e. triples + graph identifier) assessed. The aim of this study was primarily to define a number of quality metrics from various best practices and guidelines, and to assess the level of conformance of the assessed datasets against these metrics. The quality metrics considered in our work overlap with seven metrics defined in [33]: (i) avoiding blank nodes; (ii) keeping URIs short; (iii) avoiding prolix features; (iv) re-using existing terms; (v) dereferenceability of resources; (vi) usage of external URIs; and (vii) human-readable metadata. The metrics in our assessment are similar to those in [33], with some adjustments as we explain in Section 5. Apart from a larger set of quality metrics in this article, one must point out that two corpuses are different, where in [33] the authors used data crawled from the Web of Data. Nevertheless, the conclusions from [33] are more or less the same, four years later, that publishers might forgo certain quality guidelines as they might be impractical. This can be seen from the distribution of quality metric values amongst the datasets, in both studies. Färber et al. [21], give a systematic comparison of the quality of five knowledge graphs: DBpedia, Wikidata, Freebase, OpenCyc, and Yago. These knowledge graphs were assessed over 34 quality metrics, most of which are also included in our empirical study. The study performed by Färber et al. demonstrates that the KGs perform differently across most metrics, mainly dependent on issues such as the choice of modelling. Nonetheless, there are some of the quality metrics where all KGs either conform to, for example the syntactic validity of literals, or otherwise vary in their conformance, for example in the case of the inconsistencies regarding the range of relations metric. The five KGs assessed in [21] have more or less similar problems to those described in our empirical study, however, due to the lack of depth in terms of the variety of datasets assessed in their study, it makes a comparison between studies difficult. For example, if the description of resources metric are compared, Färber et al. study with five KGs resulted in a mean value of 94% (including DBpedia which was part of both studies), whilst our study gives us a far lower value of 43.76% due to the fact that there are a larger number of low scoring datasets that penalises the overall mean value. Therefore, Färber’s et al. study can be looked as being complementary to our empirical study performed on the LOD cloud, scrutinising in more detail large cross- 4 J. Debattista et al. / Evaluating the Quality of the LOD Cloud: An Empirical Investigation domain KGs, rather than giving an overview of the quality of a number of varied domain datasets. Whilst this study is of utmost importance, unfortunately the results from Färber et al. study are only available in a non-structured format; CSV. Buil-Aranda et al. [4] conducted a number of longterm experiments, mostly related to availability quality (extrinsic) metrics on around 480 SPARQL endpoints. The authors report that only one third of the endpoints have descriptive metadata such as VoID and service descriptions5 , whilst the query response performance varies widely from one endpoint to another. Our experiments confirm the performance variation and show that no single solution is available for streaming all triples directly from the endpoint (cf. Section 5.7). The authors also propose SPARQLES6 , a tool for monitoring the availability of public SPARQL endpoints (among other tests). With SPARQLES, consumers can make informed decisions more easily on whether a certain SPARQL endpoint is reliable and suitable for the task at hand. The quality of literals in the Web of Data was analysed in [8], by means of a toolchain that was implemented and integrated into LODLaundromat [9]. Beek et al. looked and assessed various properties of literals. The authors identified a taxonomy of literals that can be grouped in two types: datatype literals and language tagged literals. These two had various metrics implemented, two of which are (a) checking the validity of a datatype against its lexical value; and (b) checking the consistency between a literal’s string text against the given language tag using an external language identification service. These two were implemented in Luzzu with the former metric being discussed in our empirical survey on the LOD cloud datasets. In a recent study Assaf et al. [5] shed light on the quality of the metadata of datasets available in the Linked Open Data Cloud. This metadata was used in our dataset acquisition process. In [5], the metadata is checked for general, access, ownership and provenance information. The authors concluded, that metadata quality is in a bad condition. More specifically, licensing and accessibility metadata contains noisy data, resulting in incorrect information. We discuss the quality of LOD Cloud metadata in more detail in Section 3. Suominen and Mader [56], define a number of quality metrics in order to assess SKOS vocabularies with 5http://www.w3.org/TR/sparql11-servicedescription/ 6http://sparqles.ai.wu.ac.at/ the aim of identifying their re-use in applications. The assessment is based on three categories: (i) labelling and documentation; (ii) structural issues (e.g. class disjointness issues); and (iii) Linked Data issues (e.g. invalid URIs). The authors reported that most of their representative SKOS vocabularies contained structural errors, and presented a set of correction algorithms to address such issues. These issues discussed in [56] are also relevant to linked datasets, which we also discuss in this article, however in Suominen and Mader’s article these intrinsic and extrinsic aspects are discussed in light of Linked Data vocabularies, more specifically SKOS-driven vocabularies. In [24], Giménez-García et al. focus on dataset reuse to assess the trust of Linked Datasets. The authors use LOD Laundromat data dumps in order to compute PageRank values on datasets and rank these datasets based on their trustworthiness value. Results show that popular datasets such as DBpedia and Geonames feature in the top 10, however their approach also captures services such as purl.org, which hosts multiple datasets. In this paper we assess trustworthiness from a different aspect, by analysing provenance information of a dataset. Meusel and Paulheim in [42] analyse a number of quality issues in schema.org for Microdata and compare the results with the findings using linked datasets in [31]. The metrics studied in [42] include: (i) usage of undefined types and properties; (ii) misuse of datatype or object properties; (iii) violation of datatypes; and (iv) incorrect usage of property domain and range. The analysis performed in [42] shows that the Microdata formats adopting schema.org are prone to be less problematic with regards to undefined elements than LOD, however fares worse in the other three metrics against the LOD results analysed in [31]. In this paper we will discuss these metrics and assess them against the 2014 version of the LOD cloud.</p><figure data-equation="" data-image="24" data-figure-category="figure" data-caption="" id="F87634431" data-image-src="/media/images/0a80c909-241d-4fbb-9c1a-d99e59c46450.svg"><div><img src="0a80c909-241d-4fbb-9c1a-d99e59c46450.svg"/></div><figcaption><span class="figure-cat-figure" data-figure-category="figure">figure 1: </span></figcaption></figure><p><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:0}]">(Abelson, , Adida, , Linksvayer, &amp; Yergler, 2012)</span><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:253222569}]">(Alexander, Cyganiak, Hausenblas, &amp; Zhao, 2011)</span></p></div>
                    	</section></div><h1 class="article-bibliography-header"></h1><section id="references">
			            <h2>References</h2>
                        <div datatype="rdf:HTML" rel="schema:hasPart" typeof="deo:Reference">
                            <ol>
  <li><cite>Abelson, , Adida, , Linksvayer, &amp; Yergler (Eds.). (2012). The creative commons rights expression language. In The Digital Public Domain: Foundations for an Open Culture. Open Book Publishers.</cite></li>
  <li><cite>Alexander, Cyganiak, Hausenblas, &amp; Zhao (Eds.). (2011). Describing linked datasets with the VoID vocabulary. W3C interest group note, World Wide Web Consortium,.</cite></li>
</ol>
			            </div>
                    </section>
			    </div>
			</article>
		</main>
	</body>
</html>