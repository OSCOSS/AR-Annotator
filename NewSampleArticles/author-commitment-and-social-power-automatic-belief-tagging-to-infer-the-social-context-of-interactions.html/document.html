<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:base="http://www.dc4plus.com/references/rdf_sem.html" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:foaf="http://xmlns.com/foaf/0.1/" >
    <head>
        <title>Author Commitment and Social Power: Automatic Belief Tagging to Infer the Social Context of Interactions</title>
        
        <meta charset="utf-8" />
        <meta content="width=device-width, initial-scale=1" name="viewport" />
        <link href="https://dokie.li/media/css/basic.css" media="all" rel="stylesheet" title="Basic" />
        <link disabled="" href="https://dokie.li/media/css/lncs.css" media="all" rel="stylesheet alternate" title="LNCS" />
        <link href="https://dokie.li/media/css/acm.css" media="all" rel="stylesheet" title="ACM" />
        <link href="https://dokie.li/media/css/do.css" media="all" rel="stylesheet" />
        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" rel="stylesheet" />
        <script src="https://dokie.li/scripts/simplerdf.js"></script>
        <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
        <script src="https://dokie.li/scripts/do.js"></script><script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    </head>
	<body about="" id="article" typeof="schema:ScholarlyArticle sioc:Post prov:Entity foaf:Document sioc:Post biblio:Paper bibo:Document as:Article" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#">
        <main>
            <article about="" typeof="schema:Article">
	  	        <div class="article-content" id="content">
                    
                    <p><div class="article-part article-title" property="schema:name"><h1 class="article-part article-title" property="schema:name">Author Commitment and Social Power: Automatic Belief Tagging to Infer the Social Context of Interactions</h1></div></p><div class="article-part metadata article-authors" id="authors"><dd id="VinodkumarPrabhakaranEmail:vinod@cs.stanford.edu(StanfordUniversity)" rel="bibo:authorList" resource="#VinodkumarPrabhakaranEmail:vinod@cs.stanford.edu(StanfordUniversity)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Vinodkumar Prabhakaran <i>Email: vinod@cs.stanford.edu</i> (Stanford University)
                        </span>
                    </dd><dd id="PremkumarGaneshkumarEmail:prem@agolo.com(Agolo,Inc.)" rel="bibo:authorList" resource="#PremkumarGaneshkumarEmail:prem@agolo.com(Agolo,Inc.)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Premkumar  Ganeshkumar <i>Email: prem@agolo.com</i> (Agolo, Inc. )
                        </span>
                    </dd><dd id="OwenRambowEmail:owenr@elementalcognition.com(ElementalCognition,Inc.)" rel="bibo:authorList" resource="#OwenRambowEmail:owenr@elementalcognition.com(ElementalCognition,Inc.)">
                        <span rel="schema:creator schema:publisher schema:author" typeof="schema:person">
                            Owen Rambow <i>Email: owenr@elementalcognition.com</i> (Elemental Cognition, Inc. )
                        </span>
                    </dd></div><p><section id="Abstract" class="article-part metadata article-abstract" datatype="rdf:HTML" property="schema:abstract"><p>Understanding how social power structures affect the way we interact with one another is of great interest to social scientists who want to answer fundamental questions about human behavior, as well as to computer scientists who want to build automatic methods to infer the social contexts of interactions. In this paper, we employ advancements in extrapropositional semantics extraction within NLP to study how author commitment reflects the social context of an interactions. Specifi- cally, we investigate whether the level of commitment expressed by individuals in an organizational interaction reflects the hierarchical power structures they are part of. We find that subordinates use significantly more instances of non-commitment than superiors. More importantly, we also find that subordinates attribute propositions to other agents more often than superiors do — an aspect that has not been studied before. Finally, we show that enriching lexical features with commitment labels captures important distinctions in social meanings.</p></section></p><div class="article-part article-body"><section id="1Introduction" inlist="" rel="schema:hasPart" resource="#1Introduction">
                            <h2 property="schema:name">1 Introduction</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#1Introduction" typeof="deo:Introduction">
			                <p> Social power is a difficult concept to define, but is often manifested in how we interact with one another. Understanding these manifestations is important not only to answer fundamental questions in social sciences about power and social interactions, but also to build computational models that can automatically infer social power structures from interactions. The availability and access to large digital repositories of naturally occurring social interactions and the advancements in natural language processing techniques in recent years have enabled researchers to perform large scale studies on linguistic correlates of power, such as words and phrases (Bramsen et al., 2011; Gilbert, 2012), linguistic coordination (DanescuNiculescu-Mizil et al., 2012), agenda control (Taylor et al., 2012), and dialog structure (Prabhakaran and Rambow, 2014). Another area of research that has recently garnered interest within the NLP community is the modeling of author commitment in text. Initial studies in this area were done in processing hedges, uncertainty and lack of commitment, specifically focused on scientific text (Mercer et al., 2004; Di Marco et al., 2006; Farkas et al., 2010). More recently, researchers have also looked into capturing author commitment in nonscientific text, e.g., levels of factuality in newswire (Saur´ı and Pustejovsky, 2009), types of commitment of beliefs in a variety of genres including conversational text (Diab et al., 2009; Prabhakaran et al., 2015). These approaches are motivated from an information extraction perspective, for instance in aiding tasks such as knowledge base population.1 However, it has not been studied whether such sophisticated author commitment analysis can go beyond what is expressed in language and reveal the underlying social contexts in which language is exchanged. In this paper, we bring together these two lines of research; we study how power relations correlate with the levels of commitment authors express in interactions. We use the power analysis framework built by Prabhakaran and Rambow (2014) to perform this study, and measure author commitment using the committed belief tagging framework introduced by (Diab et al., 2009) that distinguishes different types of beliefs expressed in text. Our contributions are two-fold — statistical analysis of author commitment in relation with power, and enrichment of lexical features with commitment labels to aid in computational prediction of power relations. In the first part, we find that au- 1The BeSt track of the 2017 TAC-KBP evaluation aimed at detecting the “belief and sentiment of an entity toward another entity, relation, or event” (http://www.cs. columbia.edu/˜rambow/best-eval-2017/). thor commitment is significantly correlated with the social power relations between their participants — subordinates use more instances of noncommitment, a finding that is in line with sociolinguistics studies in this area. We also find that subordinates use significantly more reported beliefs (i.e., attributing beliefs to other agents) than superiors. This is a new finding; to our knowledge, there has not been any sociolinguistics studies investigating this aspect of interaction in relation with power. In the second part, we present novel ways of incorporating the author commitment information into lexical features that can capture important distinctions in word meanings conveyed through the belief contexts in which they occur; distinctions that are lost in a model that conflates all occurrences of a word into one unit. We first describe the related work in computational power analysis and computational modeling of cognitive states in Section 2. In Section 3, we describe the power analysis framework we use. Section 4 formally defines the research questions we are investigating, and describes how we obtain the belief information. In Section 5, we present the statistical analysis of author commitment and power. Section 6 presents the utility of enriching lexical features with belief labels in the context of automatic power prediction. Section 7 concludes the paper and summarizes the results. </p></div>
                    	</section><section id="2RelatedWork" inlist="" rel="schema:hasPart" resource="#2RelatedWork">
                            <h2 property="schema:name">2 Related Work </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#2RelatedWork" typeof="deo:RelatedWork">
			                <p>The notion of belief that we use in this paper (Diab et al., 2009; Prabhakaran et al., 2015) is closely related to the notion of factuality that is captured in FactBank (Saur´ı and Pustejovsky, 2009). They capture three levels of factuality, certain (CT), probable (PB), and possible (PS), as well as the underspecified factuality (Uu). They also record the corresponding polarity values, and the source of the factuality assertions to distinguish between factuality assertions by the author and those by the agents/sources introduced by the author. While FactBank offers a finer granularity, they are annotated on newswire text. Hence, we use the corpus of belief annotations (Prabhakaran et al., 2015) that is obtained on online discussion forums, which is closer to our genre. Automatic hedge/uncertainty detection is a very closely related task to belief detection. The belief tagging framework we use aims to capture the cognitive states of authors, whereas hedges are linguistic expressions that convey one of those cognitive states — non-committed beliefs. Automatic hedge/uncertainty detection has generated active research in recent years within the NLP community. Early work in this area focused on detecting speculative language in scientific text (Mercer et al., 2004; Di Marco et al., 2006; Kilicoglu and Bergler, 2008). The open evaluation as part of the CoNLL shared task in 2010 to detect uncertainty and hedging in biomedical and Wikipedia text (Farkas et al., 2010) triggered further research on this problem in the general domain (Agarwal and Yu, 2010; Morante et al., 2010; Velldal et al., 2012; Choi et al., 2012). Most of this work was aimed at formal scientific text in English. More recent work has tried to extend this work to other genres (Wei et al., 2013; Sanchez and Vogel, 2015) and languages (Velupillai, 2012; Vincze, 2014), as well as building general purpose hedge lexicons (Prokofieva and Hirschberg, 2014). In our work, we use the lexicons from (Prokofieva and Hirschberg, 2014) to capture hedges in text. Sociolinguists have long studied the association between level of commitment and social contexts (Lakoff, 1973; O’Barr and Atkins, 1980; Hyland, 1998). A majority of this work studies gender differences in the use of hedges, triggered by the influential work by Robin Lakoff (Lakoff, 1973). She argued that women use linguistic strategies such as hedging and hesitations in order to adopt an unassertive communication style, which she terms “women’s language”. While many studies have found evidence to support Lakoff’s theory (e.g., (Crosby and Nyquist, 1977; Preisler, 1986; Carli, 1990)), there have also been contradictory findings (e.g., (O’Barr and Atkins, 1980)) that link the difference in the use of hedges to other social factors (e.g., power). O’Barr and Atkins (1980) argue that the use of hedges is linked more to the social positions rather than gender, suggesting to rename “women’s language” to “powerless language”. In later work, O’Barr (1982) formalized the notion of powerless language, which formed the basis of many sociolinguistics studies on social power and communication. O’Barr (1982) analyzed courtroom interactions and identified hedges and hesitations as some of the linguistic markers of “powerless” speech. However, there has not been any computational work which has looked into how power relations relate to the level of commitment expressed in text. In this paper, we use com- putational power analysis to perform a large scale data-oriented study on how author commitment in text reveals the underlying power relations. There is a large body of literature in the social sciences that studies power as a social construct (e.g., (French and Raven, 1959; Dahl, 1957; Emerson, 1962; Pfeffer, 1981; Wartenberg, 1990)) and how it relates to the ways people use language in social situations (e.g., (Bales et al., 1951; Bales, 1970; O’Barr, 1982; Van Dijk, 1989; Bourdieu and Thompson, 1991; Ng and Bradac, 1993; Fairclough, 2001; Locher, 2004)). Recent years have seen growing interest in computationally analyzing and detecting power and influence from interactions. Early work in computational power analysis used social network analysis based approaches (Diesner and Carley, 2005; Shetty and Adibi, 2005; Creamer et al., 2009) or email traffic patterns (Namata et al., 2007). Using NLP to deduce social relations from online communication is a relatively new area of active research. Bramsen et al. (2011) and Gilbert (2012) first applied NLP based techniques to predict power relations in Enron emails, approaching this task as a text classification problem using bag of words or ngram features. More recently, our work has used dialog structure features derived from deeper dialog act analysis for the task of power prediction in Enron emails (Prabhakaran and Rambow, 2014; Prabhakaran et al., 2012; Prabhakaran and Rambow, 2013). In this paper, We use the framework of (Prabhakaran and Rambow, 2014), but we analyze a novel aspect of interaction that has not been studied before — what level of commitment do the authors express in language. There has also been work on analyzing power in other genres of interactions. Strzalkowski et al. (2010) and Taylor et al. (2012) concentrate on lower-level constructs called Language Uses such as agenda control to predict power in Wikipedia talk pages. Danescu-Niculescu-Mizil et al. (2012) study how social power and linguistic coordination are correlated in Wikipedia interactions as well as Supreme Court hearings. Bracewell et al. (2012) and Swayamdipta and Rambow (2012) try to identify pursuit of power in discussion forums. Biran et al. (2012) and Rosenthal (2014) study the problem of predicting influence in Wikipedia talk pages, blogs, and other online forums. Prabhakaran et al. (2013) study manifestations of power of confidence in presidential debates. </p></div>
                    	</section><section id="3PowerinWorkplaceEmail:DataandAnalysisFramework" inlist="" rel="schema:hasPart" resource="#3PowerinWorkplaceEmail:DataandAnalysisFramework">
                            <h2 property="schema:name">3 Power in Workplace Email: Data and Analysis Framework</h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#3PowerinWorkplaceEmail:DataandAnalysisFramework" typeof="deo:Discussion">
			                <p> The focus of our study is to investigate whether the level of commitment participants express in their contributions in an interaction is related to the power relations they have with other participants, and how it can help in the problem of predicting social power. In this section, we introduce the power analysis framework as well as the data we use in this study. </p></div>
                    	</section><section id="3.1Problem" inlist="" resource="#3.1Problem">
                            <h3 property="schema:name">3.1 Problem</h3>
                        <p> In order to model manifestations of power relations in interactions, we use our interaction analysis framework from (Prabhakaran and Rambow, 2014), where we introduced the problem of predicting organizational power relations between pairs of participants based on single email threads. The problem is formally defined as follows: given an email thread t, and a related interacting participant pair (p1 , p2 ) in the thread, predict whether p1 is the superior or subordinate of p2 . In this formulation, a related interacting participant pair (RIPP) is a pair of participants of the thread such that there is at least one message exchanged within the thread between them (in either direction) and that they are hierarchically related with a superior/subordinate relation. </p></section><section id="3.2Data" inlist="" resource="#3.2Data">
                            <h3 property="schema:name">3.2 Data </h3>
                        <p>We use the same dataset we used in (Prabhakaran and Rambow, 2014), which is a version of the Enron email corpus in which the thread structure of email messages is reconstructed (Yeh and Harnly, 2006), and enriched by Agarwal et al. (2012) with gold organizational power relations, manually determined using information from Enron organizational charts. The corpus captures dominance relations between 13,724 pairs of Enron employees. As in (Prabhakaran and Rambow, 2014), we use these dominance relation tuples to obtain gold labels for the superior or subordinate relationships between pairs of participants. We use the same train-test-dev split as in (Prabhakaran and Rambow, 2014). We summarize the number of threads and related interacting participant pairs in each subset of the data in Table 1. </p></section><section id="4ResearchHypotheses" inlist="" rel="schema:hasPart" resource="#4ResearchHypotheses">
                            <h2 property="schema:name">4 Research Hypotheses </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#4ResearchHypotheses" typeof="">
			                <p>Our first objective in this paper is to perform a large scale computational analysis of author com- Description Train Dev Test Email threads 18079 8973 9144 # of RIPPs 7510 3578 3920 Table 1: Data Statistics. Row 1: number of threads in subsets of the corpus. Row 2: number of related interacting participant pairs in those subsets. RIPP: Related interacting participant pairs mitment and power relations. Specifically, we want to investigate whether the commitment authors express towards their contributions in organizational interactions is correlated with the power relations they have with other participants. Sociolinguistics studies have found some evidence to suggest that lack of commitment expressed through hedges and hesitations is associated with lower power status (O’Barr, 1982). However, in our study, we go beyond hedge word lists, and analyze different cognitive belief states expressed by authors using a belief tagging framework that takes into account the syntactic contexts within which propositions are expressed. </p></div>
                    	</section><section id="4.1ObtainingBeliefLabels" inlist="" resource="#4.1ObtainingBeliefLabels">
                            <h3 property="schema:name">4.1 Obtaining Belief Labels</h3>
                        <p> We use the committed belief analysis framework introduced by (Diab et al., 2009; Prabhakaran et al., 2015) to model different levels of beliefs expressed in text. Specifically, in this paper, we use the 4-way belief distinction — COMMITTEDBELIEF, NONCOMMITTEDBELIEF, REPORTEDBELIEF, and NONAPPLICABLE— introduced in (Prabhakaran et al., 2015).2 (Prabhakaran et al., 2015) presented a corpus of online discussion forums with over 850K words, annotating each propositional head in text with one of the four belief labels. The paper also presented an automatic belief tagger trained on this data, which we use to obtain belief labels in our data. We describe each belief label and our associated hypotheses below. </p><p><strong>Committed belief (CB)</strong>: the writer strongly believes that the proposition is true, and wants the reader/hearer to believe that. E.g.: (1) a. John will submit the report. b. I know that John is capable. 2We also performed analysis and experiments using an earlier 3-way belief distinction proposed by (Diab et al., 2009), which also yielded similar findings. We do not report the details of those analyses in this paper. As discussed earlier, lack of commitment in one’s writing/speech is identified as markers of powerless language. We thus hypothesize: H. 1. Superiors use more instances of committed belief in their messages than subordinates. </p><p><strong>Non-committed belief (NCB)</strong>: the writer explicitly identifies the proposition as something which he or she could believe, but he or she happens not to have a strong belief in, for example by using an epistemic modal auxiliary. E.g.: (2) a. John may submit the report. b. I guess John is capable. This class captures a more semantic notion of non-commitment than hedges, since the belief annotation attempts to model the underlying meaning rather than language uses, and hence captures other linguistic means of expressing noncommittedness. Following (O’Barr, 1982), we formulate the below hypothesis: H. 2. Subordinates use more instances of non committed belief in their messages than superiors. </p><p><strong>Reported belief (ROB):</strong> the writer attributes belief (either committed or non-committed) to another person or group. E.g.: (3) a. Sara says John will submit the report. b. Sara thinks John may be capable. Note that this label is only applied when the writer’s own belief in the proposition is unclear. For instance, if the first example above was Sara knows John will submit the report on-time, the writer is expressing commitment toward the proposition that John will submit the report and it will be labeled as committed belief rather than reported belief. Reported belief captures instances where the writer is in effect limiting his/her commitment towards what is stated by attributing the belief to someone else. So, in line with our hypotheses for non-committed beliefs, we formulate the following hypothesis: H. 3. Subordinates use more instances of reported beliefs in their messages than superiors. </p><p><strong>Non-belief propositions (NA):</strong> – the writer expresses some other cognitive attitude toward the proposition, such as desire or intention (4a), or expressly states that he/she has no belief about the proposition (e.g., asking a question (4b)). E.g.: (4) a. I need John to submit the report. b. Will John be capable? As per the above definition, requests for information (i.e., questions) and requests for actions are cases where the author is not expressing a belief about the proposition, but rather expressing the desire that some action be done. In the study correlating power with dialog act tags (Prabhakaran and Rambow, 2014), we found that superiors issue significantly more requests than subordinates. Hence, we expect the superiors to have significantly more non belief expressions in their messages, and formulate the following hypothesis: H. 4. Superiors use more instances of non beliefs in their messages than subordinates. </p></section><section id="4.2TestingBeliefTaggerBias" inlist="" resource="#4.2TestingBeliefTaggerBias">
                            <h3 property="schema:name">4.2 Testing Belief Tagger Bias </h3>
                        <p>NLP tools are imperfect and may produce errors, which poses a problem when using any NLP tool for sociolinguistic analysis. More than the magnitude of error, we believe that whether the error is correlated with the social variable of interest (i.e., power) is more important; e.g., is the belieftagger more likely to find ROB false-positives in subordinates text? To test whether this is the case, we performed manual belief annotation on around 500 propositional heads in our corpus. Logistic regression test revealed that the belief-tagger is equally likely to make errors (both false-positives and false-negatives, for all four belief-labels) in sentences written by subordinates as superiors (the null hypothesis accepted at p &gt; 0.05 for all eight tests). </p></section><section id="5StatisticalAnalysis" inlist="" rel="schema:hasPart" resource="#5StatisticalAnalysis">
                            <h2 property="schema:name">5 Statistical Analysis </h2>
			                <div datatype="rdf:HTML" property="schema:description" resource="#5StatisticalAnalysis" typeof="deo:Discussion">
			                <p><span class="comment ref do" data-id="3953717839" rel="schema:hasPart" typeof="dctypes:Text" resource="r-3953717839"><mark id="3953717839" property="schema:description">
                        Now that we have set up the analysis framework and research hypotheses, we present the statistical analysis of how superiors and subordinates differ in their relative use of expressions of commitment.
                    </mark><sup class="ref-annotation">
    		        <a rel="cito:hasReplyFrom" href="#3953717839" resource="http://localhost:8000/document/14//comment-3953717839">
       		              💬
                    </a>
                </sup></span></p></div>
                    	<aside class="note do"><blockquote cite="3953717839"><article id="3953717839" about="i:" typeof="oa:Annotation" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# schema: http://schema.org/ dcterms: http://purl.org/dc/terms/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# i: http://localhost:8000/document/14/#3953717839"><h3 property="schema:name" style="display:none">
    Wrishi
    <span rel="oa:motivatedBy" resource="oa:replying">replies</span>
</h3>
<dl class="author-name"><dt>Authors</dt><dd><span rel="schema:creator">
    <span about="userURI#1" typeof="schema:Person">
       <img alt="" rel="schema:image" src="https://www.gravatar.com/avatar/0397eeb87e26782f66df823775d58a71/?s=80" width="48" height="48"/>
       <a href="#"><span about="userURI#1" property="schema:name">
           Wrishi
       </span></a>
    </span>
</span></dd></dl>
<dl class="published">
    <dt>Published</dt>
    <dd>
        <a href="http://localhost:8000/document/14/#3953717839">
            <time datetime="1540461391941" datatype="xsd:dateTime" property="schema:datePublished" content="1540461391941">
                1540461391941
            </time>
        </a>
    </dd>
</dl>
<section id="comment-3953717839" rel="oa:hasBody" resource="i:#comment-3953717839">
    <h2 property="schema:name">Comment</h2>
    <div datatype="rdf:HTML" property="rdf:value schema:description" resource="i:#comment-3953717839" typeof="oa:TextualBody">
        There you go
    </div>
</section>

<br/><br/></article></blockquote></aside></section><section id="5.1Features" inlist="" resource="#5.1Features">
                            <h3 property="schema:name">5.1 Features</h3>
                        <p>For each participant of each pair of related interacting participants in our corpus, we aggregate each of the four belief tags: • CBCount: number of propositional heads tagged as Committed Belief (CB) • NCBCount: number of propositional heads tagged as Non Committed Belief (NCB) • ROBCount: number of propositional heads tagged as Reported Belief (ROB) • NACount: number of propositional heads tagged as Non Belief (NA) </p></section><section id="5.2HypothesesTesting" inlist="" resource="#5.2HypothesesTesting">
                            <h3 property="schema:name">5.2 Hypotheses Testing </h3>
                        <p>Our general hypothesis is that power relations do correlate with the level of commitment people express in their messages; i.e., at least one of H.1 - H.4 is true. In this analysis, each participant of the pair (p1 , p2 ) is a data instance. We exclude the instances for which a feature value is undefined.3 In order to test whether superiors and subordinates use different types of beliefs, we used a linear regression based analysis. For each feature, we built a linear regression model predicting the feature value using power (i.e., superior vs. subordinate) as the independent variable. Since verbosity of a participant can be highly correlated with each of these feature values (we found it to be highly correlated with subordinates (Prabhakaran and Rambow, 2014)), we added token count as a control variable to the linear regression. Our linear regression test revealed significant differences in NCB (b=-.095, t(-8.09), p&lt;.001), ROB (b=-.083, t(-7.162), p&lt;.001) and NA (b=.125, t(4.351), p&lt;.001), and no significant difference in CB (b=.007, t(0.227), p=0.821). Figure 1 pictorially demonstrates these results by plotting the difference between the mean values of each commitment feature (here normalized by token count) of superiors vs. subordinates, as a percentage of mean feature value of the corresponding commitment feature for superiors. Dark bars denote statistically significant differences. </p></section><section id="5.3InterpretationofFindings" inlist="" resource="#5.3InterpretationofFindings">
                            <h3 property="schema:name">5.3 Interpretation of Findings </h3>
                        <p>The results from our statistical analysis validate our original hypothesis that power relations do correlate with the level of commitment people express in their messages. This finding remains statistically significant (p &lt; 0.001) even after applying the Bonferroni correction for multiple testing. The results on NCB confirm our hypothesis that subordinates use more non-committedness in their language. Subordinates’ messages contain 48% more instances of non-committed belief than superiors’ messages, even after normalizing for the length of messages. This is in line with prior sociolinguistics literature suggesting that people with 3These are instances corresponding to participants who did not send any messages in the thread (some of the pairs in the set of related interacting participant pairs only had oneway communication) or whose messages were empty (e.g., forwarding messages).</p><figure data-equation="" data-image="18" data-figure-category="figure" data-caption="" id="F59126251" data-image-src="/media/images/6d3ee852-3bba-4dbe-af9b-2193bc46d144.png"><div><img src="6d3ee852-3bba-4dbe-af9b-2193bc46d144.png"/></div><figcaption><span class="figure-cat-figure" data-figure-category="figure">figure 1: </span></figcaption></figure><p><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:0}]">(Agarwal, Omuya, Harnly, &amp; Rambow, 2012)</span><span class="citation" data-format="autocite" data-references="[{&quot;id&quot;:3883253975}]">(Agarwal, Omuya, Zhang, &amp; Rambow, 2014)</span></p></section></div><h1 class="article-bibliography-header"></h1><section id="references">
			            <h2>References</h2>
                        <div datatype="rdf:HTML" rel="schema:hasPart" typeof="deo:Reference">
                            <ol>
  <li><cite>Agarwal, A., Omuya, A., Harnly, A., &amp; Rambow, O. (Eds.). (2012). A comprehensive gold standard for the Enron organizational hierarchy.</cite></li>
  <li><cite>Agarwal, A., Omuya, A., Zhang, J., &amp; Rambow, O. (Eds.). (2014). In Proceedings of the 2014 International Conference on Social Computing.</cite></li>
</ol>
			            </div>
                    </section><script>jQuery( document ).ready(function() {
    			        jQuery(this).find('span.comment').each(function () {
                            var id=jQuery(this).attr('data-id');
                            var top=jQuery(this).offset().top - 40;
                            jQuery(document).find('article[id="'+id+'"]').each(function () {
                                jQuery(this).css('top',top);
                            });
                        });
                    });</script>
			    </div>
			</article>
		</main>
	</body>
</html>